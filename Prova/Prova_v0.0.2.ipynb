{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](https://doity.com.br/media/doity/eventos/evento-20025-logo_organizador.png)\n",
    "\n",
    "# Prova de Descoberta do Conhecimento\n",
    "\n",
    "* **Prof. Cleilton Lima Rocha**\n",
    "* **emails:** cleilton_rocha@atlantico.com.br; climarocha@gmail.com\n",
    "* **deadline: 17/10 às 12h **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este projeto exploraremos os dados Call_Data disponível na pasta. Para maiores informações acesse este [link](https://data.seattle.gov/Public-Safety/Call-Data/33kz-ixgy). A variável alvo da nossa prova será 'Event Clearance Description'\n",
    "\n",
    "O objetivo do nosso projeto é apoiar os policiais quanto as medidas prescritivas que eles devem tomar ao tentarem resolver uma chamada. Para isto eles têm disponível o histórico de tudo o que já foi resolvido, por ele e por seus colegas, e sua solução de Data Science =D.\n",
    "\n",
    "**PS.:**\n",
    "* Quando houver necessidade de splitar os dados aplique a proporção 70 para treino e 30 para teste\n",
    "* Quando houver necessidade de utilizar o random_state defina o valor 100\n",
    "* Envie o código fonte e o report (File ==> Download As ==> Html ou PDF), com o nome dos membros da dupla, para um dos meus emails, climarocha@gmail.com ou cleilton_rocha@atlantico.com.br até o dia **17/10 às 12h**, após esta data, 17/12 as 12h, será subtraído uma penalidade da sua nota, **penalty=(1,5/performance_modelo)**. A data limite para entrega é **18/10 às 8h**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questões obrigatórias\n",
    "\n",
    " * **1. Importe o data set train_call_data e considere a variável alvo 'Event Clearance Description'**\n",
    "     * **1.1. Como está o balanceamento das classes?**\n",
    "     * **P.S.: Não é obrigatório aplicar o undersampling and oversampling sobre o dataset**. \n",
    "     * **P.S.: Você pode usar qualquer um dos datasets de treinamento a v1 ou a v2**. \n",
    " * **2. Realize o EDA que você julgar necessário (análise exploratória dos dados), o objetivo do EDA é mostrar alguns insights sobre os dados **\n",
    "     * *Utilize recursos visuais, por exemplo gráficos* \n",
    " * **3. Realize o tratamento que você julgar mais adequado aos dados.**\n",
    "     * *P.S.: Explique, com suas palavras, porque o processo de feature engineering é necessário*\n",
    "     * *P.S.: A criação de um pipeline lhe dará pontos extras e melhorará o reaproveitamento de código *\n",
    " * **4. Selecione duas soluções candidatas e justifique suas escolhas. Mostre os pontos negativos e positivos de cada modelo.**\n",
    " * **5. Construa os modelos de aprendizagem de máquina para cada modelo **    \n",
    " * **6. Para cada modelo aplique uma combinação aos hiperparâmetros com o GridSearch e aplique também o CrossValidation**\n",
    "     * *P.S.: Explique, com suas palavras, a necessidade de utilizar GridSearch e CrossValidation*\n",
    "     * *P.S.: Explique a importância para de no mínimo um hiperparâmetro para um modelo *\n",
    " * **7. Defina uma métrica de avaliação e avalie as soluções candidatas. Justifique a escolha da sua métrica.**\n",
    " * **8. Escolha um dos modelos, por exemplo o melhor modelo, e faça uma análise do overfitting e underfitting. Justique sua resposta com base em experimentos.**\n",
    "     * *Analise no mínimo 2 hiperparâmetros e também o número de amostras utilizado no treinamento* \n",
    "     * *Utilize recursos visuais, por exemplo gráficos, se você achar neccessário* \n",
    " * **9. Realize a predição sobre os dado test_call_data, como o seu modelo saiu? **\n",
    " * **10. Se seu modelo permitir analisar a importância das features, analise-o e tente justificar de forma subjetiva a importância da feature. Por exemplo, a feature_chamadas_a_noite possui um alto coeficiente, pois há uma tendência dos crimes acontecerem a noite, não tão simples assim :P. **\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questões opcionais\n",
    " * **11. Crie ao menos 5 chamadas fake e utilize o seu modelo adicionando, no mínimo, 2 variações para a variável \"Final Call Type\" para cada amostra, logo sua amostra terá #chamadas * #variações_final_call_type. ** \n",
    " Uma das variáveis que provavelmente pode ter uma forte correlação com a variável dependente é a variável \"Final Call Type\". Por isso, você deve fornecer opções para aquela variável, a fim de auxiliar o policial na sua resolução final. Quando ele simular  novos atendimentos, a classificação da chamada inicial pode mudar, ao decorrer do seu atendimento, e de acordo com esta mudança ele saberá melhor o que fazer. Pense neste approach como uma solução real. \n",
    " * **12. Aplique clusterização, preferencialmente o KMeans sobre o dado, e comunique suas novas descobertas, sinta-se a vontade para apresentar uma solução simples ou mais robusta =D. Esta questão vale pontos extras **\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bom trabalho!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
